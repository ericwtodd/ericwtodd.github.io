<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Eric Todd</title>
    <link rel="stylesheet" href="styles.css">
    <script src="script.js" defer></script>
    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
    <!-- Academic Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
</head>

<body>
    <header class="top-strip">
        <div class="top-container">
        <nav class="top-nav">
            <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="files/Curriculum_Vitae.pdf">CV</a></li>
            <li><a href="publications.html">Publications</a></li>
            <!-- Add more links as needed -->
            </ul>
        </nav>
        </div>
    </header>

    <div class="container">
        <div class="sidebar">
            <img src="images/eric_profile.jpg" alt="Eric Todd" class="profile-pic">
            <div class="social-links">
              <a href="mailto:todd.er@northeastern.edu"><i class="fas fa-envelope fa-lg"></i><span> Email</span></a>
              <a href="https://twitter.com/ericwtodd" target="_blank"><i class="fab fa-fw fa-twitter-square"></i><span> Twitter</span></a>
              <a href="https://github.com/ericwtodd" target="_blank"><i class="fab fa-github fa-lg"></i><span> Github</span></a>
              <a href="https://www.linkedin.com/in/eric-w-todd/" target="_blank"><i class="fab fa-fw fa-linkedin"></i><span> LinkedIn</span></a>
              <a href="https://scholar.google.com/citations?hl=en&user=o12WPZEAAAAJ&view_op=list_works&sortby=pubdate" target="_blank"><i class="ai ai-google-scholar" style="font-size:1.3rem"></i><span> Google Scholar</span></a>
            </div>
          </div>

        <div class="main-content">
            <section id="conference-publications">
                <h2>Conference Publications</h2>

                <div class="citation">
                    Jaden Fiotto-Kaufman, Alexander R. Loftus, <b>Eric Todd</b>, Jannik Brinkmann, Koyena Pal, Dmitrii Troitskii, 
                    Michael Ripa, Adam Belfki, Can Rager, Caden Juang, Aaron Mueller, Samuel Marks, Arnab Sen Sharma, Francesca Lucchetti, Nikhil Prakash, 
                    Carla Brodley, Arjun Guha, Jonathan Bell, Byron C. Wallace, David Bau. 
                    <a href="https://arxiv.org/pdf/2407.14561">NNsight and NDIF: Democratizing Access to Open-Weight Foundation Model Internals.</a> <em>Proceedings of the 2025 International Conference on Learning Representations.</em> (ICLR 2025)
                    <div class="publication-content">
                        <div class="button-container">
                            <button class="abstract-toggle">Abstract</button>
                            <a href="https://nnsight.net"><button>NNsight Website</button></a>
                            <a href="https://ndif.us"><button>NDIF Website</button></a>
                            <a href="https://arxiv.org/abs/2407.14561"><button>PDF</button></a>
                            <a href="https://openreview.net/forum?id=MxbEiFRf39"><button>OpenReview</button></a>
                            <div class="abstract-container">
                                <p> We introduce NNsight and NDIF, technologies that work in tandem to enable
                                    scientific study of very large neural networks. NNsight is an open-source system
                                    that extends PyTorch to introduce deferred remote execution. NDIF is a scalable
                                    inference service that executes NNsight requests, allowing users to share GPU
                                    resources and pretrained models. These technologies are enabled by the intervention graph, 
                                    an architecture developed to decouple experiment design from model
                                    runtime. Together, this framework provides transparent and efficient access to
                                    the internals of deep neural networks such as very large language models (LLMs)
                                    without imposing the cost or complexity of hosting customized models individually.
                                    We conduct a quantitative survey of the machine learning literature that reveals
                                    a growing gap in the study of the internals of large-scale AI. We demonstrate
                                    the design and use of our framework to address this gap by enabling a range of
                                    research methods on huge models. Finally, we conduct benchmarks to compare
                                    performance with previous approaches. Code, documentation, and tutorials are
                                    available at <a href="https://nnsight.net/">https://nnsight.net/</a>.</p>
                                </div>
                            </div>
                        </div> 
                </div>
                    
                <div class="citation">
                    <b>Eric Todd</b>, Millicent L. Li, Arnab Sen Sharma, Aaron Mueller, Byron C. Wallace, David Bau. 
                    <a href="https://arxiv.org/pdf/2310.15213">Function Vectors in Large Language Models.</a> 
                    <em>Proceedings of the 2024 International Conference on Learning Representations.</em> (ICLR 2024)
                    <div class="publication-content">
                        <div class="button-container">
                            <button class="abstract-toggle">Abstract</button>
                            <a href="https://functions.baulab.info"><button>Project Website</button></a>
                            <a href="https://arxiv.org/abs/2310.15213"><button>PDF</button></a>
                            <a href="https://openreview.net/forum?id=AwyxtyMwaG"><button>OpenReview</button></a>
                            <div class="abstract-container">
                                <p>We report the presence of a simple neural mechanism that represents an input-output function as a vector 
                                    within autoregressive transformer language models (LMs). Using causal mediation analysis on a diverse range 
                                    of in-context-learning (ICL) tasks, we find that a small number attention heads transport a compact representation 
                                    of the demonstrated task, which we call a function vector (FV). FVs are robust to changes in context, i.e., 
                                    they trigger execution of the task on inputs such as zero-shot and natural text settings that do not resemble the ICL contexts 
                                    from which they are collected. We test FVs across a range of tasks, models, and layers and find strong causal effects across settings in middle layers.
                                    We investigate the internal structure of FVs and find while that they often contain information that encodes the output space of the function, 
                                    this information alone is not sufficient to reconstruct an FV. Finally, we test semantic vector composition in FVs,
                                    and find that to some extent they can be summed to create vectors that trigger new complex tasks. Our findings show that compact, 
                                    causal internal vector representations of function abstractions can be explicitly extracted from LLMs.</p>
                            </div>
                        </div>
                    </div>
                </div> 

                <div class="citation">
                    <b>Eric Todd</b>, Mylan R. Cook, Katrina Pedersen, David S. Woolworth, Brooks A. Butler, Xin Zhao,
                    Colt Liu, Kent L. Gee, Mark K. Transtrum, Sean Warnick. 
                    <a href="https://pubs.aip.org/asa/poma/article/39/1/040003/838127/Automatic-detection-of-instances-of-focused-crowd">Automatic detection of instances of
                        focused crowd involvement at recreational events.</a> <em>Proceedings of Meetings on Acoustics</em> <b>39</b>, 040003. (2019)
                    <div class="publication-content">
                        <div class="button-container">
                            <button class="abstract-toggle">Abstract</button>
                            <a href="files/automatic-detection-of-focused-crowd-involvement.pdf"><button>PDF</button></a>
                            <!-- <a href="https://pubs.aip.org/asa/poma/article/39/1/040003/838127/Automatic-detection-of-instances-of-focused-crowd"><button>POMA</button></a> -->
                            <div class="abstract-container">
                                <p>This paper describes the development of an automated classification algorithm for detecting instances of focused
                                    crowd involvement present in crowd cheering. The purpose of this classification system is for situations where crowds
                                    are to be rewarded for not just the loudness of cheering, but for a concentrated effort, such as in Mardi Gras parades to
                                    attract bead throws or during critical moments in sports matches. It is therefore essential to separate non-crowd noise,
                                    general crowd noise, and focused crowd cheering efforts from one another. The importance of various features—both
                                    spectral and low-level audio processing features—are investigated. Data from both parades and sporting events are
                                    used for comparison of noise from different venues. This research builds upon previous clustering analyses of crowd
                                    noise from collegiate basketball games, using hierarchical clustering as an unsupervised machine learning approach to
                                    identify low-level features related to focused crowd involvement. For Mardi Gras crowd data we use a continuous
                                    thresholding approach based on these key low-level features as a method of identifying instances where the crowd is
                                    particularly active and engaged.</p>
                            </div>
                        </div>
                    </div>
                </div> 

                <div class="citation">
                    Brooks A. Butler, Katrina Pedersen, Mylan R. Cook, Spencer G. Wadsworth, <b>Eric Todd</b>, Dallen Stark, Kent L. Gee, Mark K. Transtrum, Sean Warnick.
                    <a href="https://pubs.aip.org/asa/poma/article/35/1/055006/997305/Classifying-crowd-behavior-at-collegiate">Classifying crowd behavior at collegiate basketball games using acoustic data.</a> <em>Proceedings of Meetings on Acoustics</em> <b>35</b>, 055006. (2018)
                    <div class="publication-content">
                        <div class="button-container">
                            <button class="abstract-toggle">Abstract</button>
                            <a href="files/classifying-crowd-behavior-basketball.pdf"><button>PDF</button></a>                            
                            <!-- <a href="https://pubs.aip.org/asa/poma/article/35/1/055006/997305/Classifying-crowd-behavior-at-collegiate"><button>Link</button></a> -->
                            <div class="abstract-container">
                                <p>The relationship between crowd noise and crowd behavioral dynamics is a relatively unexplored field of
                                    research. Signal processing and machine learning (ML) may be useful in classifying and predicting crowd
                                    emotional state. This paper describes using both supervised and unsupervised ML methods to
                                    automatically differentiate between different types of crowd noise. Features used include A-weighted
                                    spectral levels, low-level audio signal parameters, and Mel-frequency cepstral coefficients. K-means
                                    clustering is used for the unsupervised approach with spectral levels, and six distinct clusters are found;
                                    four of these clusters correspond to different amounts of crowd involvement, while two correspond to
                                    different amounts of band or public announcement system noise. Random forests are used for the
                                    supervised approach, wherein validation and testing accuracies are found to be similar. These
                                    investigations are useful for differentiating between types of crowd noise, which is necessary for future
                                    work in automatically determining and classifying crowd emotional state. </p>
                            </div>
                        </div>
                    </div>
                </div> 

            </section>

            <hr>
            
            <section id="preprints">
            <h2>Preprints and In Submission</h2>

                <div class="citation">
                    Lee Sharkey, Bilal Chughtai, Joshua Batson, Jack Lindsey, Jeff Wu, Lucius Bushnaq, Nicholas Goldowsky-Dill, Stefan Heimersheim, 
                    Alejandro Ortega, Joseph Bloom, Stella Biderman, Adria Garriga-Alonso, Arthur Conmy, Neel Nanda, Jessica Rumbelow, Martin Wattenberg, 
                    Nandi Schoots, Joseph Miller, Eric J. Michaud, Stephen Casper, Max Tegmark, William Saunders, David Bau, <b>Eric Todd</b>, Atticus Geiger, 
                    Mor Geva, Jesse Hoogland, Daniel Murfet, Tom McGrath.
                    <a href="https://arxiv.org/abs/2501.16496">Open Problems in Mechanistic Interpretability.</a> 2025.
                    <div class="publication-content">
                        <div class="button-container">
                            <button class="abstract-toggle">Abstract</button> 
                            <a href="https://arxiv.org/pdf/2501.16496"><button>PDF</button></a>
                            <div class="abstract-container">
                                <p> Mechanistic interpretability aims to understand the computational mechanisms underlying neural networks' capabilities
                                    in order to accomplish concrete scientific and engineering goals. Progress in this field thus promises to provide greater assurance
                                    over AI system behavior and shed light on exciting scientific questions about the nature of intelligence. 
                                    Despite recent progress toward these goals, there are many open problems in the field that require solutions before many scientific and practical benefits can be realized:
                                    Our methods require both conceptual and practical improvements to reveal deeper insights;
                                    we must figure out how best to apply our methods in pursuit of specific goals; and the field must grapple with socio-technical challenges that influence and are influenced by our work. 
                                    This forward-facing review discusses the current frontier of mechanistic interpretability and the open problems that the field may benefit from prioritizing.</p>
                                </div>
                            </div>
                        </div> 
                </div>

                <div class="citation">
                    Aaron Mueller, Jannik Brinkmann, Millicent Li, Samuel Marks, Koyena Pal, Nikhil Prakash, Can Rager, Aruna Sankaranarayanan, Arnab Sen Sharma, Jiuding Sun, <b>Eric Todd</b>, David Bau, Yonatan Belinkov. 
                    <a href="https://arxiv.org/abs/2408.01416">The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability.</a> 2024.
                    <div class="publication-content">
                        <div class="button-container">
                            <button class="abstract-toggle">Abstract</button>
                            <!-- <a href=""><button>Project Website</button></a> -->
                            <a href="https://arxiv.org/pdf/2408.01416"><button>PDF</button></a>
                            <div class="abstract-container">
                                <p> Interpretability provides a toolset for understanding how and why neural networks behave in certain ways. 
                                    However, there is little unity in the field: most studies employ ad-hoc evaluations and do not share theoretical foundations, 
                                    making it difficult to measure progress and compare the pros and cons of different techniques. 
                                    Furthermore, while mechanistic understanding is frequently discussed, the basic causal units underlying these mechanisms 
                                    are often not explicitly defined. In this paper, we propose a perspective on interpretability research grounded in causal mediation analysis.
                                    Specifically, we describe the history and current state of interpretability taxonomized according to the types of 
                                    causal units (mediators) employed, as well as methods used to search over mediators. We discuss the pros and cons of each mediator, 
                                    providing insights as to when particular kinds of mediators and search methods are most appropriate depending on the goals of a given study. 
                                    We argue that this framing yields a more cohesive narrative of the field, as well as actionable insights for future work. 
                                    Specifically, we recommend a focus on discovering new mediators with better trade-offs between human-interpretability and compute-efficiency,
                                    and which can uncover more sophisticated abstractions from neural networks than the primarily linear mediators employed in current work.
                                    We also argue for more standardized evaluations that enable principled comparisons across mediator types, such that we can better understand
                                    when particular causal units are better suited to particular use cases</p>
                                </div>
                            </div>
                        </div> 
                </div>

                <!-- <div class="citation">
                    AUTHORS HERE <a href="">TITLE HERE</a> YEAR.
                    <div class="publication-content">
                        <div class="button-container">
                            <button class="abstract-toggle">Abstract</button>
                            <a href=""><button>Project Website</button></a> 
                            <a href=""><button>PDF</button></a>
                            <div class="abstract-container">
                                <p> ABSTRACT HERE</p>
                                </div>
                            </div>
                        </div> 
                </div> -->

            </section>

            <hr>
            <footer>
                <p class="copyright">&copy; 2025 Eric Todd. All rights reserved. Last updated on March 19, 2025.</p>
            </footer>
        
        </div>

    </div>

</body>

</html>


